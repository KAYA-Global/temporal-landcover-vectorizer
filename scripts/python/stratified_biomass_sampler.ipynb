{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ulfboge/temporal-landcover-vectorizer/blob/main/scripts/python/stratified_biomass_sampler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjN37WTuU13_"
      },
      "source": [
        "# Spatial Data Sampling and Integration\n",
        "\n",
        "This notebook:\n",
        "1. Processes multiple CSV files containing temporal spatial data\n",
        "2. Creates a unified long-format table\n",
        "3. Samples biomass data in equal intervals\n",
        "4. Integrates corresponding NDVI and NDFI values\n",
        "\n",
        "## Setup\n",
        "First, let's mount Google Drive and import required libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vReaNc6qU14B",
        "outputId": "fbe29831-11ec-4861-eb0c-38e251f42b32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nNE5aXqNU14C"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Set the working directory\n",
        "csv_dir = \"/content/drive/MyDrive/earthengine/conversion/csv\"\n",
        "output_dir = \"/content/drive/MyDrive/earthengine/conversion/output\"\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECNFWOVLU14C"
      },
      "source": [
        "## Process CSV Files\n",
        "Read and transform CSV files into long format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "e-q94FU2U14C",
        "outputId": "9659f116-bed6-46d0-f97b-64500a0c8bff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed biomass_Area_6_vectorized.csv\n",
            "Processed biomass_Area_5_vectorized.csv\n",
            "Processed biomass_Area_7_vectorized.csv\n",
            "Processed biomass_Area_8_vectorized.csv\n"
          ]
        }
      ],
      "source": [
        "def process_csv_to_long_format(file_path):\n",
        "    # Extract the data type from filename (NDVI, NDFI, or biomass)\n",
        "    data_type = Path(file_path).stem.split('_')[0].upper()\n",
        "\n",
        "    # Read CSV\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Identify year columns (starting with 'y')\n",
        "    year_cols = [col for col in df.columns if col.startswith('y')]\n",
        "\n",
        "    # Melt the dataframe to long format\n",
        "    long_df = pd.melt(\n",
        "        df,\n",
        "        id_vars=['pixel_id'],  # Removed x_coord and y_coord\n",
        "        value_vars=year_cols,\n",
        "        var_name='year',\n",
        "        value_name=data_type\n",
        "    )\n",
        "\n",
        "    # Convert year format from 'y2013' to '2013'\n",
        "    long_df['year'] = long_df['year'].str.replace('y', '')\n",
        "\n",
        "    return long_df\n",
        "\n",
        "# Process all CSV files\n",
        "dfs = {}\n",
        "for file in os.listdir(csv_dir):\n",
        "    if file.endswith('.csv'):\n",
        "        file_path = os.path.join(csv_dir, file)\n",
        "        data_type = Path(file).stem.split('_')[0].upper()\n",
        "        dfs[data_type] = process_csv_to_long_format(file_path)\n",
        "        print(f\"Processed {file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FlVYt-SU14D"
      },
      "source": [
        "## Sample Biomass Data\n",
        "Sample 100 points from biomass data with equal distribution across intervals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DKpOTXWAU14D",
        "outputId": "e0e36436-10ca-411a-de7f-bf2850f52d4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique pixels sampled: 100\n"
          ]
        }
      ],
      "source": [
        "# Define intervals\n",
        "intervals = [(5, 34), (35, 64), (65, 94), (95, 124), (125, 150)]\n",
        "samples_per_interval = 20  # 20 samples per interval = 100 total\n",
        "\n",
        "# Filter and sample biomass data\n",
        "biomass_df = dfs['BIOMASS']\n",
        "sampled_pixels = []\n",
        "\n",
        "for start, end in intervals:\n",
        "    # Filter data within interval\n",
        "    interval_data = biomass_df[\n",
        "        (biomass_df['BIOMASS'] >= start) &\n",
        "        (biomass_df['BIOMASS'] <= end)\n",
        "    ]\n",
        "\n",
        "    # Sample from this interval\n",
        "    if len(interval_data) >= samples_per_interval:\n",
        "        sampled = interval_data.sample(n=samples_per_interval, random_state=42)\n",
        "    else:\n",
        "        sampled = interval_data  # Take all available if less than needed\n",
        "        print(f\"Warning: Only {len(interval_data)} samples available for interval {start}-{end}\")\n",
        "\n",
        "    sampled_pixels.extend(sampled['pixel_id'].unique())\n",
        "\n",
        "print(f\"Total unique pixels sampled: {len(set(sampled_pixels))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uk3BgHp_U14D"
      },
      "source": [
        "## Integrate Data\n",
        "Combine data from all sources using sampled pixel IDs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "s6KuwYPpU14D",
        "outputId": "a90355c6-b76a-48a9-c574-a1a7967c3886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to: /content/drive/MyDrive/earthengine/conversion/output/sampled_data.csv\n",
            "\n",
            "First few rows of the result:\n"
          ]
        }
      ],
      "source": [
        "# Filter each dataset for sampled pixels\n",
        "filtered_dfs = {}\n",
        "for data_type, df in dfs.items():\n",
        "    filtered_dfs[data_type] = df[df['pixel_id'].isin(sampled_pixels)]\n",
        "\n",
        "# Merge all datasets - excluding x_coord and y_coord\n",
        "result = filtered_dfs['BIOMASS'][['pixel_id', 'year', 'BIOMASS']]\n",
        "for data_type in ['NDVI', 'NDFI']:\n",
        "    if data_type in filtered_dfs:\n",
        "        result = result.merge(\n",
        "            filtered_dfs[data_type][['pixel_id', 'year', data_type]],\n",
        "            on=['pixel_id', 'year'],\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "# Sort the results\n",
        "result = result.sort_values(['pixel_id', 'year'])\n",
        "\n",
        "# Save the results\n",
        "output_path = os.path.join(output_dir, 'sampled_data.csv')\n",
        "result.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Results saved to: {output_path}\")\n",
        "print(\"\\nFirst few rows of the result:\")\n",
        "display(result.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e393LbFU14D"
      },
      "source": [
        "## Summary Statistics\n",
        "Display summary of the sampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "b1QPY66LU14E",
        "outputId": "368246a0-9b16-4a93-9074-ec2f86bf6fed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary of sampled data:\n",
            "Total unique pixels: 100\n",
            "Years covered: ['2013', '2015', '2017', '2019']\n",
            "\n",
            "Value ranges:\n",
            "BIOMASS:\n",
            "  Min: 3.00\n",
            "  Max: 206.00\n",
            "  Mean: 77.27\n"
          ]
        }
      ],
      "source": [
        "print(\"Summary of sampled data:\")\n",
        "print(f\"Total unique pixels: {result['pixel_id'].nunique()}\")\n",
        "print(f\"Years covered: {sorted(result['year'].unique())}\")\n",
        "print(\"\\nValue ranges:\")\n",
        "for column in ['BIOMASS', 'NDVI', 'NDFI']:\n",
        "    if column in result.columns:\n",
        "        print(f\"{column}:\")\n",
        "        print(f\"  Min: {result[column].min():.2f}\")\n",
        "        print(f\"  Max: {result[column].max():.2f}\")\n",
        "        print(f\"  Mean: {result[column].mean():.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}