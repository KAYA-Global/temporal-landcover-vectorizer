{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/your-repo/sample_data_processor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Data Sampling and Integration\n",
    "\n",
    "This notebook:\n",
    "1. Processes multiple CSV files containing temporal spatial data\n",
    "2. Creates a unified long-format table\n",
    "3. Samples biomass data in equal intervals\n",
    "4. Integrates corresponding NDVI and NDFI values\n",
    "\n",
    "## Setup\n",
    "First, let's mount Google Drive and import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set the working directory\n",
    "csv_dir = \"/content/drive/MyDrive/earthengine/conversion/csv\"\n",
    "output_dir = \"/content/drive/MyDrive/earthengine/conversion/output\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process CSV Files\n",
    "Read and transform CSV files into long format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv_to_long_format(file_path):\n",
    "    # Extract the data type from filename (NDVI, NDFI, or biomass)\n",
    "    data_type = Path(file_path).stem.split('_')[0].upper()\n",
    "    \n",
    "    # Read CSV\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Identify year columns (starting with 'y')\n",
    "    year_cols = [col for col in df.columns if col.startswith('y')]\n",
    "    \n",
    "    # Melt the dataframe to long format\n",
    "    long_df = pd.melt(\n",
    "        df,\n",
    "        id_vars=['pixel_id', 'x_coord', 'y_coord'],\n",
    "        value_vars=year_cols,\n",
    "        var_name='year',\n",
    "        value_name=data_type\n",
    "    )\n",
    "    \n",
    "    # Convert year format from 'y2013' to '2013'\n",
    "    long_df['year'] = long_df['year'].str.replace('y', '')\n",
    "    \n",
    "    return long_df\n",
    "\n",
    "# Process all CSV files\n",
    "dfs = {}\n",
    "for file in os.listdir(csv_dir):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_dir, file)\n",
    "        data_type = Path(file).stem.split('_')[0].upper()\n",
    "        dfs[data_type] = process_csv_to_long_format(file_path)\n",
    "        print(f\"Processed {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Biomass Data\n",
    "Sample 100 points from biomass data with equal distribution across intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define intervals\n",
    "intervals = [(5, 34), (35, 64), (65, 94), (95, 124), (125, 150)]\n",
    "samples_per_interval = 20  # 20 samples per interval = 100 total\n",
    "\n",
    "# Filter and sample biomass data\n",
    "biomass_df = dfs['BIOMASS']\n",
    "sampled_pixels = []\n",
    "\n",
    "for start, end in intervals:\n",
    "    # Filter data within interval\n",
    "    interval_data = biomass_df[\n",
    "        (biomass_df['BIOMASS'] >= start) & \n",
    "        (biomass_df['BIOMASS'] <= end)\n",
    "    ]\n",
    "    \n",
    "    # Sample from this interval\n",
    "    if len(interval_data) >= samples_per_interval:\n",
    "        sampled = interval_data.sample(n=samples_per_interval, random_state=42)\n",
    "    else:\n",
    "        sampled = interval_data  # Take all available if less than needed\n",
    "        print(f\"Warning: Only {len(interval_data)} samples available for interval {start}-{end}\")\n",
    "    \n",
    "    sampled_pixels.extend(sampled['pixel_id'].unique())\n",
    "\n",
    "print(f\"Total unique pixels sampled: {len(set(sampled_pixels))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate Data\n",
    "Combine data from all sources using sampled pixel IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter each dataset for sampled pixels\n",
    "filtered_dfs = {}\n",
    "for data_type, df in dfs.items():\n",
    "    filtered_dfs[data_type] = df[df['pixel_id'].isin(sampled_pixels)]\n",
    "\n",
    "# Merge all datasets\n",
    "result = filtered_dfs['BIOMASS'][['pixel_id', 'x_coord', 'y_coord', 'year', 'BIOMASS']]\n",
    "for data_type in ['NDVI', 'NDFI']:\n",
    "    if data_type in filtered_dfs:\n",
    "        result = result.merge(\n",
    "            filtered_dfs[data_type][['pixel_id', 'year', data_type]],\n",
    "            on=['pixel_id', 'year'],\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "# Sort the results\n",
    "result = result.sort_values(['pixel_id', 'year'])\n",
    "\n",
    "# Save the results\n",
    "output_path = os.path.join(output_dir, 'sampled_data.csv')\n",
    "result.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Results saved to: {output_path}\")\n",
    "print(\"\\nFirst few rows of the result:\")\n",
    "display(result.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "Display summary of the sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary of sampled data:\")\n",
    "print(f\"Total unique pixels: {result['pixel_id'].nunique()}\")\n",
    "print(f\"Years covered: {sorted(result['year'].unique())}\")\n",
    "print(\"\\nValue ranges:\")\n",
    "for column in ['BIOMASS', 'NDVI', 'NDFI']:\n",
    "    if column in result.columns:\n",
    "        print(f\"{column}:\")\n",
    "        print(f\"  Min: {result[column].min():.2f}\")\n",
    "        print(f\"  Max: {result[column].max():.2f}\")\n",
    "        print(f\"  Mean: {result[column].mean():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
